# -*- coding: utf-8 -*-
"""Clustering.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1a-sggLArA937RN5J-KNnyAbfsmPKmkzL
"""

import csv
import pandas as pd
import os
import numpy as np
import pathlib
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt
from yellowbrick.cluster import KElbowVisualizer, InterclusterDistance

pd.set_option('display.max_columns', None)

# Conecta o serviço com o Drive
from google.colab import drive
drive.mount('/content/drive')

# Root Path
os.environ['ROOT'] = '/content/drive/MyDrive/Mestrado/Ordens_servico/'
base_path = os.environ.get("ROOT")

year = 2022

# Raiz
! ls '/content/drive/MyDrive/Mestrado/Ordens_servico/'

"""# Interrupcoes"""

interrupcoes = pd.read_csv("/content/drive/MyDrive/Mestrado/Ordens_servico/Ordens_servico/test_interrupcoes_collect_ckan_{}.csv".format(year))

interrupcoes

# Datetime difference
# (pd.to_datetime(interrupcoes["DatFimInterrupcao"]) - pd.to_datetime(interrupcoes["DatInicioInterrupcao"])).dt.components['hours']
(pd.to_datetime(interrupcoes["DatFimInterrupcao"]) - pd.to_datetime(interrupcoes["DatInicioInterrupcao"]))

# Get the total hours of the interruption
interrupcoes["Duration"] = ((pd.to_datetime(interrupcoes["DatFimInterrupcao"]) - pd.to_datetime(interrupcoes["DatInicioInterrupcao"])).dt.seconds / 60 / 60) # convert second to minute and after hours
interrupcoes["Duration"] = (np.round(interrupcoes["Duration"], 2))
interrupcoes["Duration"]

# Histrogram of the interruptions

fig, ax = plt.subplots()

ax.tick_params(axis='x', labelrotation = 90)
ax.set_ylabel('Densidade de Ocorrência - %')
ax.set_xlabel('Tempo de interrupção em horas')

weights = np.ones_like(interrupcoes["Duration"]) / len(interrupcoes["Duration"])
values = ax.hist(interrupcoes["Duration"], bins= 100, color="grey", weights=weights)

# Histrogram of the interruptions
fig, ax = plt.subplots()

ax.tick_params(axis='x', labelrotation = 90)
ax.set_ylabel('Densidade de Ocorrência - Total Acumulado - %')
ax.set_xlabel('Tempo de interrupção em horas')

ax.hist(interrupcoes["Duration"], bins= 100, color="grey", density=True, cumulative=True)

"""Dado que alguns registros apresentam intervalos de duração de interrupções maiores do que 20 horas, é avaliado a porcentagem de registros que se encontram neste caso."""

interrupcoes[interrupcoes.Duration > 20].shape[0] / interrupcoes.shape[0]

"""### Grafico da quantidade de interrupcoes por tempo de cada interrupcao

Grupo 1 - Alta quantidade de interrupções e tempo de religamento alto

Grupo 2 - Baixa quantidade de interrupções e tempo de religamnto alto

Grupo 3 - Alta quantidade de interrupções e tempo de religamento baixo

Grupo 4 - Baixa quantidade de interrupcoes e tempo de religamento baixo

Para a divisao dos grupos é realizado uma regra de acordo com cada grupo. Da forma que no grupo 1 ficam clientes com mais do que 50% da quantidade média de interrupcoes e mais de 5 horas de interrupcao (aproximadamente 70% dos casos da base em 2021). No grupo 2 ficam os cliente com menos de 50% do total de interrupções e mais de 5 horas de interrupcoes. No grupo 3 ficam os clientes com mais de 50% do total de interrupcoes e menos de 5 horas de interrupcao e no grupo 4 os clientes com mais de 50% de interrupcoes e menos de 5 horas de interrupcao. Estas sao as divisoes realizadas.
"""

interrupcoes_agg = interrupcoes.groupby("DscConjuntoUnidadeConsumidora").agg({'Duration': 'mean', "DscConjuntoUnidadeConsumidora": 'count'}).rename(columns={"Duration": "Mean_Duration", "DscConjuntoUnidadeConsumidora": "Qtd_Interrupcoes"})

interrupcoes_agg["Mean_Qtd_Interrupcoes"] = interrupcoes_agg.Qtd_Interrupcoes.mean()

total = interrupcoes_agg.shape[0]
g1 = interrupcoes_agg[(interrupcoes_agg["Qtd_Interrupcoes"] > interrupcoes_agg.Mean_Qtd_Interrupcoes) & (interrupcoes_agg["Mean_Duration"] < 5)].shape[0]
g2 = interrupcoes_agg[(interrupcoes_agg["Qtd_Interrupcoes"] > interrupcoes_agg.Mean_Qtd_Interrupcoes) & (interrupcoes_agg["Mean_Duration"] > 5)].shape[0]
g3 = interrupcoes_agg[(interrupcoes_agg["Qtd_Interrupcoes"] < interrupcoes_agg.Mean_Qtd_Interrupcoes) & (interrupcoes_agg["Mean_Duration"] > 5)].shape[0]
g4 = interrupcoes_agg[(interrupcoes_agg["Qtd_Interrupcoes"] < interrupcoes_agg.Mean_Qtd_Interrupcoes) & (interrupcoes_agg["Mean_Duration"] < 5)].shape[0]

total, g1, g2, g3, g4

"""# Applie the K-means"""

interrupcoes_agg = interrupcoes_agg[["Qtd_Interrupcoes", "Mean_Duration"]]

# Realiza a normalizacao dos dados para as colunas numericas - Para o modelo eh necessario normalizar (colocar as variaveis entre 0 e 1) porque pode ser que um atributo tenha
# mais impacto que outro
# O tratamento eh aplicado para todo o conjunto porque todo o conjunto ja eh numerico
from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()

features = [col for col in interrupcoes_agg.columns]

# Scale only the features because the scale of the output dont impact the convergence
scaler.fit(interrupcoes_agg[features])
interrupcoes_agg[features] = scaler.transform(interrupcoes_agg[features])

interrupcoes_agg

kmeans = KMeans(n_clusters=4, random_state=0, n_init="auto").fit(interrupcoes_agg)

kmeans.cluster_centers_

! pip install yellowbrick

visualizer = KElbowVisualizer(KMeans(), k=(1,12))

visualizer.fit(interrupcoes_agg)        # Fit the data to the visualizer
visualizer.show()        # Finalize and render the figure

model = KMeans(n_clusters=4, random_state=0, n_init="auto")

model.fit(interrupcoes_agg)

interrupcoes_agg["labels"] = model.labels_

interrupcoes_agg

import seaborn as sns

ax = sns.scatterplot(data=interrupcoes_agg, x=interrupcoes_agg["Qtd_Interrupcoes"], y=interrupcoes_agg["Mean_Duration"], hue=interrupcoes_agg["labels"], palette="crest")


ax.set(ylabel='Duracao media das Interrupcoes (horas)', xlabel='Quantidade de Interrupções', title='Representacao de clusters da quantidade e duracao de interrupcoes por conjunto de unidades consumidoras')

print("Quantidade de Clusters")
interrupcoes_agg["labels"].value_counts()

interrupcoes_agg.index

# Transform the clusters labels to string, the model receive it as a categorical data
interrupcoes_agg["labels"] = interrupcoes_agg["labels"].astype("str")

interrupcoes_agg["labels"].to_csv(base_path + "Ordens_servico/cluster_grps.csv")

